{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0304884c-acff-4bed-884a-aebc3fa183cc",
   "metadata": {},
   "source": [
    "# SoftMax Implemention details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af35add-47fb-4e51-a5d1-a8d18244b4c4",
   "metadata": {},
   "source": [
    "[torch 里使用默认使用logsoftmax](https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Softmax)\n",
    "\n",
    "```\n",
    "\n",
    "note::\n",
    "        This module doesn't work directly with NLLLoss,\n",
    "        which expects the Log to be computed between the Softmax and itself.\n",
    "        Use `LogSoftmax` instead (it's faster and has better numerical properties).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949979f0-b26b-4954-800e-b0fdb7256632",
   "metadata": {},
   "source": [
    "## Safe-Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc09123-a063-407c-9b69-5faa6b7eed32",
   "metadata": {},
   "source": [
    "先实现基本的[safe-softmax](https://ogunlao.github.io/2020/04/26/you_dont_really_know_softmax.html)\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "sm(x_i) = \\dfrac{e^{x_i - c}}{\\sum_{j=1}^{d} e^{x_j -c}}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb6279-26d9-42c7-8ca3-54c3164bba3d",
   "metadata": {},
   "source": [
    "## Safe Softmax implemention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9004ed3-528f-431a-a706-38bc1696fac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">原始数据:\n",
       " <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.9187</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.7027</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.4287</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3837</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5099</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9975</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5943</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.9596</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3548</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5438</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "原始数据:\n",
       " \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1.9187\u001b[0m, \u001b[1;36m-0.7027\u001b[0m, \u001b[1;36m-1.4287\u001b[0m,  \u001b[1;36m0.3837\u001b[0m, \u001b[1;36m-0.5099\u001b[0m,  \u001b[1;36m0.9975\u001b[0m, \u001b[1;36m-0.5943\u001b[0m, \u001b[1;36m-0.9596\u001b[0m,\n",
       "         \u001b[1;36m1.3548\u001b[0m,  \u001b[1;36m0.5438\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">softmax:\n",
       " <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3612</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0263</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0127</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0778</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0318</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1438</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0293</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0203</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2055</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0913</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "softmax:\n",
       " \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3612\u001b[0m, \u001b[1;36m0.0263\u001b[0m, \u001b[1;36m0.0127\u001b[0m, \u001b[1;36m0.0778\u001b[0m, \u001b[1;36m0.0318\u001b[0m, \u001b[1;36m0.1438\u001b[0m, \u001b[1;36m0.0293\u001b[0m, \u001b[1;36m0.0203\u001b[0m, \u001b[1;36m0.2055\u001b[0m,\n",
       "        \u001b[1;36m0.0913\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">prob sum:\n",
       " <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "prob sum:\n",
       " \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">logprob:\n",
       " <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0183</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.6397</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.3658</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.5533</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.4470</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.9396</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.5314</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.8966</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5822</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.3932</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "logprob:\n",
       " \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.0183\u001b[0m, \u001b[1;36m-3.6397\u001b[0m, \u001b[1;36m-4.3658\u001b[0m, \u001b[1;36m-2.5533\u001b[0m, \u001b[1;36m-3.4470\u001b[0m, \u001b[1;36m-1.9396\u001b[0m, \u001b[1;36m-3.5314\u001b[0m, \u001b[1;36m-3.8966\u001b[0m,\n",
       "        \u001b[1;36m-1.5822\u001b[0m, \u001b[1;36m-2.3932\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "def SoftMax(logits):\n",
    "    '''\n",
    "    logits: [batch_size, dim]\n",
    "    output: [batch_size, dim]\n",
    "    '''\n",
    "    logits_max, _ = logits.max(dim = -1)\n",
    "    logits = logits - logits_max.unsqueeze(1) \n",
    "    logits = logits.exp()\n",
    "    logits_sum = logits.sum(-1, keepdim = True)\n",
    "    prob = logits / logits_sum\n",
    "    return prob.abs()\n",
    "    \n",
    "logits = torch.randn(8, 10)\n",
    "prob = SoftMax(logits)\n",
    "print('原始数据:\\n', logits[0]) \n",
    "print('softmax:\\n', prob[0]) \n",
    "print('prob sum:\\n',prob[0,:].sum())\n",
    "print('logprob:\\n', prob[0].log())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca8d32-8652-4de1-bbf2-dd0b141ee566",
   "metadata": {},
   "source": [
    "# LogSoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c692c3d-d970-4b5b-beab-4a6c37fe56da",
   "metadata": {},
   "source": [
    "## Softmax overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af121a-b581-4e03-a901-076e5e8905a2",
   "metadata": {},
   "source": [
    "在MLE(最大似然估计中)， 通常要计算logprob(), 以下例子产生了数值溢出: -inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c267ffe5-e76e-46af-9d73-eca6b2e17903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m   \u001b[1;36m10\u001b[0m,     \u001b[1;36m2\u001b[0m, \u001b[1;36m10000\u001b[0m,     \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>-inf, -inf, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m-inf, -inf, \u001b[1;36m0\u001b[0m., -inf\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 这个例子取log后，会产生数值不稳定性\n",
    "logits = torch.tensor([[10, 2, 10000, 4]])\n",
    "prob = SoftMax(logits)\n",
    "print(logits)\n",
    "print(prob)\n",
    "print(prob.log())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4f1e7-c372-4f62-b7ec-d40662a42057",
   "metadata": {},
   "source": [
    "## LogSoftmax Implemention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc5fee-bd6f-4a24-855b-26a1b2f9ca20",
   "metadata": {},
   "source": [
    "在pytorch的实现中，使用logsoftmax代替softmax，避免计算logprob产生溢出\n",
    "\n",
    "可以在原始的Softmax上加入log, 可以推导出logsoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7091c5a-7ca6-41ec-b317-09e04da312ca",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\text{softmax}(x_i) &= \\dfrac{e^{x_i - c}}{\\sum_{j=1}^{d} e^{x_j -c}} \\\\\n",
    "\\text{log\\_softmax}(x_i) &= \\log \\dfrac{e^{x_i - c}}{\\sum_{j=1}^{d} e^{x_j -c}} \\\\\n",
    "\\text{log\\_softmax}(x_i) &= x_i - c - \\log {\\sum_{j=1}^{d} e^{x_j -c}} \\\\\n",
    "\\end{align} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047bdf6-004a-49fe-beea-1a140e950b83",
   "metadata": {},
   "source": [
    "此时的logsoftmax得出的logprob不会溢出，同样可以将logprob转化成prob\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\dfrac{e^{\\log~probs}}{\\sum_{j=1}^{d} e^{\\log~probs}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5959889c-5426-4266-ba48-20211dc911f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------softmax------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------softmax------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">softmax probs: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1917</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1129</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1068</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1768</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4119</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4423</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1075</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3130</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0445</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0928</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "softmax probs: \n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1917\u001b[0m, \u001b[1;36m0.1129\u001b[0m, \u001b[1;36m0.1068\u001b[0m, \u001b[1;36m0.1768\u001b[0m, \u001b[1;36m0.4119\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4423\u001b[0m, \u001b[1;36m0.1075\u001b[0m, \u001b[1;36m0.3130\u001b[0m, \u001b[1;36m0.0445\u001b[0m, \u001b[1;36m0.0928\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">softmax_log_probs: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.6520</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.1815</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.2365</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.7328</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.8871</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.8158</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.2306</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1616</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.1126</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.3776</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "softmax_log_probs: \n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.6520\u001b[0m, \u001b[1;36m-2.1815\u001b[0m, \u001b[1;36m-2.2365\u001b[0m, \u001b[1;36m-1.7328\u001b[0m, \u001b[1;36m-0.8871\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.8158\u001b[0m, \u001b[1;36m-2.2306\u001b[0m, \u001b[1;36m-1.1616\u001b[0m, \u001b[1;36m-3.1126\u001b[0m, \u001b[1;36m-2.3776\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------log softmax------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------log softmax------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">logsoftmax probs: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1917</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1129</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1068</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1768</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4119</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4423</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1075</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3130</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0445</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0928</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "logsoftmax probs: \n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1917\u001b[0m, \u001b[1;36m0.1129\u001b[0m, \u001b[1;36m0.1068\u001b[0m, \u001b[1;36m0.1768\u001b[0m, \u001b[1;36m0.4119\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4423\u001b[0m, \u001b[1;36m0.1075\u001b[0m, \u001b[1;36m0.3130\u001b[0m, \u001b[1;36m0.0445\u001b[0m, \u001b[1;36m0.0928\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">logsoftmax_log_probs: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.6520</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.1815</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.2365</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.7328</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.8871</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.8158</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.2306</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1616</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.1126</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.3776</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "logsoftmax_log_probs: \n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.6520\u001b[0m, \u001b[1;36m-2.1815\u001b[0m, \u001b[1;36m-2.2365\u001b[0m, \u001b[1;36m-1.7328\u001b[0m, \u001b[1;36m-0.8871\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.8158\u001b[0m, \u001b[1;36m-2.2306\u001b[0m, \u001b[1;36m-1.1616\u001b[0m, \u001b[1;36m-3.1126\u001b[0m, \u001b[1;36m-2.3776\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "def LogSoftMax(logits, recover_prob = True):\n",
    "    '''\n",
    "    logits: [batch_size, dim]\n",
    "    output: [batch_size, dim]\n",
    "    '''\n",
    "    # raw_logits = logits\n",
    "    logits_max, _ = logits.max(dim = -1)\n",
    "    safe_logits = logits - logits_max.unsqueeze(1)\n",
    "    safe_logits_exp = safe_logits.exp()\n",
    "    safe_logits_sum = safe_logits_exp.sum(-1, keepdim = True)\n",
    "    log_logits_sum = safe_logits_sum.log()\n",
    "    log_probs = logits - logits_max.unsqueeze(1) - log_logits_sum\n",
    "\n",
    "    if recover_prob is True:\n",
    "        exp_log_probs = log_probs.exp()\n",
    "        sum_log_probs = exp_log_probs.sum(-1, keepdim = True)\n",
    "        probs = exp_log_probs / sum_log_probs\n",
    "    \n",
    "    return probs, log_probs \n",
    "    \n",
    "logits = torch.randn(2, 5)\n",
    "\n",
    "# softmax\n",
    "print('--------------softmax------------------')\n",
    "softmax_probs = SoftMax(logits)\n",
    "softmax_log_probs = softmax_probs.log()\n",
    "print(f'softmax probs: \\n{softmax_probs}')\n",
    "print(f'softmax_log_probs: \\n{softmax_log_probs}')\n",
    "\n",
    "# log softmax\n",
    "print('--------------log softmax------------------')\n",
    "lsoftmax_probs, lsoftmax_log_probs = LogSoftMax(logits, recover_prob = True)\n",
    "print(f'logsoftmax probs: \\n{lsoftmax_probs}')\n",
    "print(f'logsoftmax_log_probs: \\n{lsoftmax_log_probs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc3dcc-1890-4bb0-8b45-3c64fa12c79f",
   "metadata": {},
   "source": [
    "## Softmax VS LogSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e5de92-05b5-4f1a-84e9-c9b83440d158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------softmax------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------softmax------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">softmax probs: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "softmax probs: \n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">softmax_log_probs: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>-inf, -inf, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "softmax_log_probs: \n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m-inf, -inf, \u001b[1;36m0\u001b[0m., -inf\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------log softmax------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------log softmax------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">logsoftmax probs: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "logsoftmax probs: \n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">logsoftmax_log_probs: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9990</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9998</span>.,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9996</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "logsoftmax_log_probs: \n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-9990\u001b[0m., \u001b[1;36m-9998\u001b[0m.,     \u001b[1;36m0\u001b[0m., \u001b[1;36m-9996\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits = torch.tensor([[10, 2, 10000, 4]])\n",
    "\n",
    "# softmax\n",
    "softmax_probs = SoftMax(logits)\n",
    "softmax_log_probs = softmax_probs.log()\n",
    "print('--------------softmax------------------')\n",
    "print(f'softmax probs: \\n{softmax_probs}')\n",
    "print(f'softmax_log_probs: \\n{softmax_log_probs}')\n",
    "\n",
    "# log softmax\n",
    "lsoftmax_probs, lsoftmax_log_probs = LogSoftMax(logits, recover_prob = True)\n",
    "print('--------------log softmax------------------')\n",
    "print(f'logsoftmax probs: \\n{lsoftmax_probs}')\n",
    "print(f'logsoftmax_log_probs: \\n{lsoftmax_log_probs}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebd26b6-bc97-4649-9707-58e9216f24dc",
   "metadata": {},
   "source": [
    "使用`LogSoftmax()` 得到的`logprob` 不会产生`-inf`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06837c95-f02c-4234-876e-5d0f1e34efaf",
   "metadata": {},
   "source": [
    "# Pytorch LogSoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4992321-846a-4c11-a255-07864cccc46a",
   "metadata": {},
   "source": [
    "使用pytorch测试softmax是否会溢出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89b7ae1-4500-48b9-a165-1b6f10e1c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/5w4m7xtn6vs7ncl5gs5fs9600000gn/T/ipykernel_17534/742943935.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x_softmax = torch.nn.functional.softmax(x)\n",
      "/var/folders/nb/5w4m7xtn6vs7ncl5gs5fs9600000gn/T/ipykernel_17534/742943935.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x_logsoftmax = torch.nn.functional.log_softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>-inf, -inf, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m-inf, -inf, \u001b[1;36m0\u001b[0m., -inf\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9990</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9998</span>.,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9996</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-9990\u001b[0m., \u001b[1;36m-9998\u001b[0m.,     \u001b[1;36m0\u001b[0m., \u001b[1;36m-9996\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[10, 2, 10000, 4]], dtype=torch.float32)\n",
    "\n",
    "x_softmax = torch.nn.functional.softmax(x)\n",
    "\n",
    "\n",
    "x_logsoftmax = torch.nn.functional.log_softmax(x)\n",
    "\n",
    "print(x_softmax)\n",
    "\n",
    "print(x_softmax.log())\n",
    "\n",
    "print(x_logsoftmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
