{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b638f595-9e01-4787-8587-0f41e068af44",
   "metadata": {},
   "source": [
    "# CLIP Pytorh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393be7c5-47d3-4941-b336-c4c024ac2fd8",
   "metadata": {},
   "source": [
    "reference: [Transfromers](https://github.com/huggingface/transformers)\n",
    "\n",
    "Notebook Author: [xiaodongguaAIGC](https://github.com/dhcode-cpp)\n",
    "\n",
    "Author: xiaodongguaAIGC\n",
    "\n",
    "github: dhcode-cpp\n",
    "\n",
    "gmail: dhcode95@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7192a91-3b2e-46b2-a41a-0524b7ca77a2",
   "metadata": {},
   "source": [
    "![CLIP](./images/clip.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "8a5c156d-78fc-4e08-9259-7a7c8ff3715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from typing import Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037d268-cb13-4219-b287-f9bfad930a2a",
   "metadata": {},
   "source": [
    "# config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "cd80b9ea-5e41-49dc-b89c-b56848c35fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPTextConfig():\n",
    "    model_type = \"clip_text_model\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=49408,\n",
    "        hidden_size=512,\n",
    "        intermediate_size=2048,\n",
    "        projection_dim=512,\n",
    "        num_hidden_layers=12,\n",
    "        num_attention_heads=8,\n",
    "        max_position_embeddings=77,\n",
    "        # hidden_act=\"quick_gelu\",\n",
    "        hidden_act=\"gelu\",\n",
    "        layer_norm_eps=1e-5,\n",
    "        attention_dropout=0.0,\n",
    "        initializer_range=0.02,\n",
    "        initializer_factor=1.0,\n",
    "        # This differs from `CLIPTokenizer`'s default and from openai/clip\n",
    "        # See https://github.com/huggingface/transformers/pull/24773#issuecomment-1632287538\n",
    "        pad_token_id=1,\n",
    "        bos_token_id=49406,\n",
    "        eos_token_id=49407,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # super().__init__(pad_token_id=pad_token_id, bos_token_id=bos_token_id, eos_token_id=eos_token_id, **kwargs)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.projection_dim = projection_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.hidden_act = hidden_act\n",
    "        self.initializer_range = initializer_range\n",
    "        self.initializer_factor = initializer_factor\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.bos_token_id = bos_token_id\n",
    "        self.eos_token_id = eos_token_id\n",
    "\n",
    "\n",
    "class CLIPVisionConfig():\n",
    "    model_type = \"clip_vision_model\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size=768,\n",
    "        intermediate_size=3072,\n",
    "        projection_dim=512,\n",
    "        num_hidden_layers=12,\n",
    "        num_attention_heads=12,\n",
    "        num_channels=3,\n",
    "        image_size=224,\n",
    "        patch_size=32,\n",
    "        # hidden_act=\"quick_gelu\",\n",
    "        hidden_act=\"gelu\",\n",
    "        layer_norm_eps=1e-5,\n",
    "        attention_dropout=0.0,\n",
    "        initializer_range=0.02,\n",
    "        initializer_factor=1.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.projection_dim = projection_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.num_channels = num_channels\n",
    "        self.patch_size = patch_size\n",
    "        self.image_size = image_size\n",
    "        self.initializer_range = initializer_range\n",
    "        self.initializer_factor = initializer_factor\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.hidden_act = hidden_act\n",
    "\n",
    "class CLIPConfig():\n",
    "    model_type = \"clip\"\n",
    "\n",
    "    def __init__(\n",
    "        self, text_config=None, vision_config=None, projection_dim=512, logit_scale_init_value=2.6592, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.text_config = text_config\n",
    "        self.vision_config = vision_config\n",
    "\n",
    "        self.projection_dim = projection_dim\n",
    "        self.logit_scale_init_value = logit_scale_init_value\n",
    "        self.initializer_factor = 1.0\n",
    "\n",
    "        self.gradient_checkpointing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "bfc3047f-9d01-4222-bafc-ba9215118fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'text_config'</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">__main__.CLIPTextConfig</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x14ca6f0d0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'vision_config'</span><span style=\"color: #000000; text-decoration-color: #000000\">: &lt;__main__.CLIPVisionConfig object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x14cb4b610</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'projection_dim'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'logit_scale_init_value'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.6592</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'initializer_factor'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'gradient_checkpointing'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'text_config'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95m__main__.CLIPTextConfig\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x14ca6f0d0\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[32m'vision_config'\u001b[0m\u001b[39m: <__main__.CLIPVisionConfig object at \u001b[0m\u001b[1;36m0x14cb4b610\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[32m'projection_dim'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "    \u001b[32m'logit_scale_init_value'\u001b[0m: \u001b[1;36m2.6592\u001b[0m,\n",
       "    \u001b[32m'initializer_factor'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'gradient_checkpointing'\u001b[0m: \u001b[3;92mTrue\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'vocab_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49408</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'intermediate_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'projection_dim'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_hidden_layers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_attention_heads'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'max_position_embeddings'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'layer_norm_eps'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_act'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gelu'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'initializer_range'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'initializer_factor'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attention_dropout'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pad_token_id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'bos_token_id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eos_token_id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'vocab_size'\u001b[0m: \u001b[1;36m49408\u001b[0m,\n",
       "    \u001b[32m'hidden_size'\u001b[0m: \u001b[1;36m128\u001b[0m,\n",
       "    \u001b[32m'intermediate_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "    \u001b[32m'projection_dim'\u001b[0m: \u001b[1;36m128\u001b[0m,\n",
       "    \u001b[32m'num_hidden_layers'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "    \u001b[32m'num_attention_heads'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "    \u001b[32m'max_position_embeddings'\u001b[0m: \u001b[1;36m77\u001b[0m,\n",
       "    \u001b[32m'layer_norm_eps'\u001b[0m: \u001b[1;36m1e-05\u001b[0m,\n",
       "    \u001b[32m'hidden_act'\u001b[0m: \u001b[32m'gelu'\u001b[0m,\n",
       "    \u001b[32m'initializer_range'\u001b[0m: \u001b[1;36m0.02\u001b[0m,\n",
       "    \u001b[32m'initializer_factor'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'attention_dropout'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'pad_token_id'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'bos_token_id'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'eos_token_id'\u001b[0m: \u001b[1;36m2\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'intermediate_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'projection_dim'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_hidden_layers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_attention_heads'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_channels'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'patch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'initializer_range'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'initializer_factor'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attention_dropout'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'layer_norm_eps'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_act'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gelu'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'hidden_size'\u001b[0m: \u001b[1;36m128\u001b[0m,\n",
       "    \u001b[32m'intermediate_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "    \u001b[32m'projection_dim'\u001b[0m: \u001b[1;36m128\u001b[0m,\n",
       "    \u001b[32m'num_hidden_layers'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "    \u001b[32m'num_attention_heads'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "    \u001b[32m'num_channels'\u001b[0m: \u001b[1;36m3\u001b[0m,\n",
       "    \u001b[32m'patch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "    \u001b[32m'image_size'\u001b[0m: \u001b[1;36m224\u001b[0m,\n",
       "    \u001b[32m'initializer_range'\u001b[0m: \u001b[1;36m0.02\u001b[0m,\n",
       "    \u001b[32m'initializer_factor'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'attention_dropout'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'layer_norm_eps'\u001b[0m: \u001b[1;36m1e-05\u001b[0m,\n",
       "    \u001b[32m'hidden_act'\u001b[0m: \u001b[32m'gelu'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "intermediate_size = hidden_size*4\n",
    "projection_dim = hidden_size\n",
    "num_hidden_layers = 2\n",
    "num_attention_heads = 4\n",
    "num_channels = 3\n",
    "image_size = 224\n",
    "patch_size = 32\n",
    "\n",
    "vocab_size = 100\n",
    "pad_token_id = 0\n",
    "bos_token_id = 1\n",
    "eos_token_id = 2\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "clip_projection_dim = 512\n",
    "\n",
    "text_config = CLIPTextConfig(hidden_size = 128,\n",
    "                intermediate_size = hidden_size*4,\n",
    "                projection_dim = hidden_size,\n",
    "                num_hidden_layers = 2,\n",
    "                num_attention_heads = 4,\n",
    "                num_channels = 3,\n",
    "                pad_token_id = 0,\n",
    "                bos_token_id = 1,\n",
    "                eos_token_id = 2,\n",
    "                )\n",
    "\n",
    "vision_config = CLIPVisionConfig(hidden_size = 128,\n",
    "                intermediate_size = hidden_size*4,\n",
    "                projection_dim = hidden_size,\n",
    "                num_hidden_layers = 2,\n",
    "                num_attention_heads = 4,\n",
    "                num_channels = 3,\n",
    "                image_size = 224,\n",
    "                patch_size = 32)\n",
    "\n",
    "config = CLIPConfig(text_config = text_config,\n",
    "                    vision_config = vision_config,\n",
    "                    projection_dim = clip_projection_dim)\n",
    "print(config.__dict__)\n",
    "print(config.text_config.__dict__)\n",
    "print(config.vision_config.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9c0e8-b99c-434f-936e-6674817e3cb8",
   "metadata": {},
   "source": [
    "# Clip Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2c012-bf7b-4963-97e5-0a208273ab36",
   "metadata": {},
   "source": [
    "对于两个encoder，通用transformer 编码器结构，可以复用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4077cc-f690-4c9a-94cd-94d8dfe4d93d",
   "metadata": {},
   "source": [
    "## CLIP: Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "e23b520a-4951-4bd0-841f-36b626c5f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class CLIPAttention(nn.Module):\n",
    "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed_dim = config.hidden_size\n",
    "        self.num_heads = config.num_attention_heads\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "        self.dropout = config.attention_dropout\n",
    "\n",
    "        self.k_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.v_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.q_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.out_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):\n",
    "        return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        # causal_attention_mask: Optional[torch.Tensor] = None,\n",
    "        # output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \"\"\"Input shape: Batch x Time x Channel\"\"\"\n",
    "\n",
    "        bsz, tgt_len, embed_dim = hidden_states.size()\n",
    "        self.scale = 1.0 / math.sqrt(embed_dim)\n",
    "\n",
    "        # get query proj\n",
    "        query_states = self.q_proj(hidden_states) * self.scale\n",
    "        key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n",
    "        value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n",
    "\n",
    "        # split multi-head\n",
    "        proj_shape = (bsz * self.num_heads, -1, self.head_dim)\n",
    "        query_states = self._shape(query_states, tgt_len, bsz).view(*proj_shape)\n",
    "        key_states = key_states.view(*proj_shape)\n",
    "        value_states = value_states.view(*proj_shape)\n",
    "\n",
    "        # scaled dot product attention\n",
    "        src_len = key_states.size(1)\n",
    "        attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
    "        if attention_mask is not None:\n",
    "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask\n",
    "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
    "\n",
    "        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
    "\n",
    "        attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "        attn_output = torch.bmm(attn_probs, value_states)\n",
    "\n",
    "        # output proj\n",
    "        attn_output = attn_output.view(bsz, self.num_heads, tgt_len, self.head_dim)\n",
    "        attn_output = attn_output.transpose(1, 2)\n",
    "        attn_output = attn_output.reshape(bsz, tgt_len, embed_dim)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "\n",
    "        attn_weights_reshaped = None\n",
    "        return attn_output, attn_weights_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "5bbde521-e3a1-4088-8115-b2a69a3997eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>k_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>v_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>q_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCLIPAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mk_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mv_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mq_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 10\n",
    "\n",
    "clip_attention = CLIPAttention(text_config)\n",
    "print(clip_attention)\n",
    "x_embd = torch.randn(batch_size, seq_len, hidden_size)\n",
    "x_attn = clip_attention(x_embd)\n",
    "print(x_attn[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "ce64a918-ec3d-45ac-87bf-4796a0ec30b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3675</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3444</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1788</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0554</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0650</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0139</span><span style=\"font-weight: bold\">]]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.3675\u001b[0m, \u001b[1;36m-1.3444\u001b[0m,  \u001b[1;36m0.1788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-1.0554\u001b[0m, \u001b[1;36m-0.0650\u001b[0m, \u001b[1;36m-1.0139\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2364</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1202</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1021</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1537</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0308</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1575</span><span style=\"font-weight: bold\">]]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.2364\u001b[0m, \u001b[1;36m-0.1202\u001b[0m,  \u001b[1;36m0.1021\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.1537\u001b[0m, \u001b[1;36m-0.0308\u001b[0m, \u001b[1;36m-0.1575\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class GELUActivation(nn.Module):\n",
    "    \"\"\"\n",
    "    Original Implementation of the GELU activation function in Google BERT repo when initially created. For\n",
    "    information: OpenAI GPT's GELU is slightly different (and gives slightly different results): 0.5 * x * (1 +\n",
    "    torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) This is now written in C in nn.functional\n",
    "    Also see the Gaussian Error Linear Units paper: https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_gelu_python: bool = False):\n",
    "        super().__init__()\n",
    "        if use_gelu_python:\n",
    "            self.act = self._gelu_python\n",
    "        else:\n",
    "            self.act = nn.functional.gelu\n",
    "\n",
    "    def _gelu_python(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return input * 0.5 * (1.0 + torch.erf(input / math.sqrt(2.0)))\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return self.act(input)\n",
    "gelu = GELUActivation()\n",
    "dummy_tensor = torch.randn(1,2,3)\n",
    "print(dummy_tensor)\n",
    "activate_tensor = gelu(dummy_tensor)\n",
    "print(activate_tensor)\n",
    "\n",
    "class ClassInstantier(OrderedDict):\n",
    "    def __getitem__(self, key):\n",
    "        content = super().__getitem__(key)\n",
    "        cls, kwargs = content if isinstance(content, tuple) else (content, {})\n",
    "        return cls(**kwargs)\n",
    "ACT2CLS = {\n",
    "    \"gelu\": GELUActivation,\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"sigmoid\": nn.Sigmoid,\n",
    "    \"silu\": nn.SiLU,\n",
    "    \"swish\": nn.SiLU,\n",
    "}\n",
    "ACT2FN = ClassInstantier(ACT2CLS)\n",
    "\n",
    "class CLIPMLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.activation_fn = ACT2FN[config.hidden_act]\n",
    "        self.fc1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.fc2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.fc1(hidden_states)\n",
    "        hidden_states = self.activation_fn(hidden_states)\n",
    "        hidden_states = self.fc2(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "719eb04d-0233-4efe-a865-1ca8252778cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPMLP</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>activation_fn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCLIPMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mactivation_fn\u001b[1m)\u001b[0m: \u001b[1;35mGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_mlp = CLIPMLP(text_config)\n",
    "print(clip_mlp)\n",
    "config.hidden_act = 'gelu'\n",
    "x_mlp = clip_mlp(x_attn[0])\n",
    "print(x_mlp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d8a4392f-7d59-4910-8ea0-d3928a13d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPEncoderLayer(nn.Module):\n",
    "    def __init__(self, config: CLIPConfig):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config.hidden_size\n",
    "        self.self_attn = CLIPAttention(config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.embed_dim, eps=config.layer_norm_eps)\n",
    "        self.mlp = CLIPMLP(config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.embed_dim, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "    ) -> torch.FloatTensor:\n",
    "        _x = x\n",
    "\n",
    "        x = self.layer_norm1(x) # prenorm\n",
    "        x, _ = self.self_attn(\n",
    "            hidden_states=x,\n",
    "            attention_mask=attention_mask,\n",
    "            # causal_attention_mask=causal_attention_mask,\n",
    "        )\n",
    "        x = _x + x\n",
    "\n",
    "        _x = x\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = _x + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "18fab4d7-a314-456b-a7f4-68dbedf6e9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPEncoderLayer</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>self_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>k_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>v_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>q_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>layer_norm1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPMLP</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>activation_fn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
       "    <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>layer_norm2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCLIPEncoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mself_attn\u001b[1m)\u001b[0m: \u001b[1;35mCLIPAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mk_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mv_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mq_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayer_norm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mCLIPMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mactivation_fn\u001b[1m)\u001b[0m: \u001b[1;35mGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayer_norm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_encoder = CLIPEncoderLayer(text_config)\n",
    "print(clip_encoder)\n",
    "config.hidden_act = 'gelu'\n",
    "x_encoder = clip_mlp(x_embd)\n",
    "print(x_encoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "27500495-c8db-41da-af75-b767aab5fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPEncoder(nn.Module):\n",
    "    def __init__(self, config: CLIPConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layers = nn.ModuleList([CLIPEncoderLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        x = x\n",
    "        for idx, encoder_layer in enumerate(self.layers):\n",
    "                x = encoder_layer(\n",
    "                    x,\n",
    "                    attention_mask,\n",
    "                )\n",
    "        x = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "3192c0a2-55e9-4ff2-87de-23b34dc33208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPEncoderLayer</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>self_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>k_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>v_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>q_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>layer_norm1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPMLP</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>activation_fn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
       "    <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>layer_norm2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCLIPEncoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mself_attn\u001b[1m)\u001b[0m: \u001b[1;35mCLIPAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mk_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mv_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mq_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayer_norm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mCLIPMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mactivation_fn\u001b[1m)\u001b[0m: \u001b[1;35mGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayer_norm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_encoders = CLIPEncoder(text_config)\n",
    "print(clip_encoders.layers[0])\n",
    "print(len(clip_encoders.layers))\n",
    "print(config.text_config.num_hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "9177fca5-7b4e-4a89-a563-b2ed1ec3c259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPEncoder</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>layers<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPEncoderLayer</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span>self_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>k_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>v_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>q_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>layer_norm1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPMLP</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>activation_fn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>layer_norm2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCLIPEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mCLIPEncoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mself_attn\u001b[1m)\u001b[0m: \u001b[1;35mCLIPAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mk_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mv_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mq_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayer_norm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mCLIPMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mactivation_fn\u001b[1m)\u001b[0m: \u001b[1;35mGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayer_norm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPEncoder</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>layers<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPEncoderLayer</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span>self_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>k_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>v_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>q_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>layer_norm1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CLIPMLP</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>activation_fn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>layer_norm2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCLIPEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mCLIPEncoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mself_attn\u001b[1m)\u001b[0m: \u001b[1;35mCLIPAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mk_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mv_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mq_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayer_norm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mCLIPMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mactivation_fn\u001b[1m)\u001b[0m: \u001b[1;35mGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayer_norm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = CLIPEncoder(config.vision_config)\n",
    "print(encoder)\n",
    "encoder = CLIPEncoder(config.text_config)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9a867-bd0a-4a34-beca-f33837d9b863",
   "metadata": {},
   "source": [
    "# CLIP: Text Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "6c574baa-5e1c-41d1-82b7-c87f72556311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CLIPTextEmbeddings(nn.Module):\n",
    "    def __init__(self, config: CLIPTextConfig):\n",
    "        super().__init__()\n",
    "        embed_dim = config.hidden_size\n",
    "\n",
    "        self.token_embedding = nn.Embedding(config.vocab_size, embed_dim)\n",
    "        self.position_embedding = nn.Embedding(config.max_position_embeddings, embed_dim)\n",
    "        self.register_buffer(\n",
    "            \"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)), persistent=False\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        seq_length = input_ids.shape[-1]\n",
    "        position_ids = self.position_ids[:, :seq_length]\n",
    "        inputs_embeds = self.token_embedding(input_ids)\n",
    "        position_embeddings = self.position_embedding(position_ids)\n",
    "        embeddings = inputs_embeds + position_embeddings\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "clip_embedding = CLIPTextEmbeddings(config.text_config)\n",
    "text_src = torch.randint(low=0, high=text_config.vocab_size-1, \n",
    "                          size=(batch_size, seq_len),\n",
    "                          dtype=torch.int)\n",
    "text_embedding = clip_embedding(text_src)\n",
    "print(text_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "77658425-7309-443e-a6f5-20c545afbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip text encoder 用的是因果建模mask\n",
    "# 所以取eos token的向量，作为text encoder\n",
    "# 对于BERT类模型，会有[CLS]token 来作为 text encoder 向量\n",
    "\n",
    "class CLIPTextTransformer(nn.Module):\n",
    "    def __init__(self, config: CLIPTextConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        embed_dim = config.hidden_size\n",
    "        self.embeddings = CLIPTextEmbeddings(config)\n",
    "        self.encoder = CLIPEncoder(config)\n",
    "        self.final_layer_norm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\n",
    "        self.eos_token_id = config.eos_token_id\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "    ) :\n",
    "\n",
    "        input_shape = input_ids.size()\n",
    "        input_ids = input_ids.view(-1, input_shape[-1])\n",
    "\n",
    "        x = self.embeddings(input_ids=input_ids,)\n",
    "\n",
    "        # attention_mask = _prepare_4d_attention_mask(attention_mask, hidden_states.dtype)\n",
    "        causal_attention_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1) * -torch.inf\n",
    "        causal_attention_mask = causal_attention_mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        x = self.encoder(\n",
    "            x,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "\n",
    "        last_hidden_state = x\n",
    "        # print(last_hidden_state.shape)\n",
    "        pooler_output = self.final_layer_norm(last_hidden_state[:,-1,:]) # poolerout\n",
    "\n",
    "        # if self.eos_token_id == 2:\n",
    "        #     # The `eos_token_id` was incorrect before PR #24773: Let's keep what have been done here.\n",
    "        #     # A CLIP model with such `eos_token_id` in the config can't work correctly with extra new tokens added\n",
    "        #     # ------------------------------------------------------------\n",
    "        #     # text_embeds.shape = [batch_size, sequence_length, transformer.width]\n",
    "        #     # left padding的情况下，最右边的token是eos-token\n",
    "        #     # take features from the eot embedding (eot_token is the highest number in each sequence) \n",
    "        #     # casting to torch.int for onnx compatibility: argmax doesn't support int64 inputs with opset 14\n",
    "        #     pooled_output = last_hidden_state[\n",
    "        #         torch.arange(last_hidden_state.shape[0], device=last_hidden_state.device),\n",
    "        #         input_ids.to(dtype=torch.int, device=last_hidden_state.device).argmax(dim=-1),\n",
    "        #     ]\n",
    "        # else:\n",
    "        #     # The config gets updated `eos_token_id` from PR #24773 (so the use of exta new tokens is possible)\n",
    "        #     pooled_output = last_hidden_state[\n",
    "        #         torch.arange(last_hidden_state.shape[0], device=last_hidden_state.device),\n",
    "        #         # We need to get the first position of `eos_token_id` value (`pad_token_ids` might equal to `eos_token_id`)\n",
    "        #         # Note: we assume each sequence (along batch dim.) contains an  `eos_token_id` (e.g. prepared by the tokenizer)\n",
    "        #         (input_ids.to(dtype=torch.int, device=last_hidden_state.device) == self.eos_token_id)\n",
    "        #         .int()\n",
    "        #         .argmax(dim=-1),\n",
    "        #     ]\n",
    "\n",
    "        return {\n",
    "            'last_hidden_state': last_hidden_state,\n",
    "            'pooler_output': pooler_output,\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "6ac4ce53-7f11-4b40-b3fe-770408227634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(config.text_config.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e1355629-1e43-4d01-b376-ba22f15bcfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(config.text_config.eos_token_id)\n",
    "clip_transformers = CLIPTextTransformer(config.text_config)\n",
    "text_src = torch.randint(low=0, high=text_config.vocab_size-1, \n",
    "                          size=(batch_size, seq_len),\n",
    "                          dtype=torch.int)\n",
    "\n",
    "result = clip_transformers(text_src)\n",
    "print(result['last_hidden_state'].shape)\n",
    "print(result['pooler_output'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "88a2e03a-b322-476b-b039-b9307a15a7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CLIPTextModel(nn.Module):\n",
    "    def __init__(self, config: CLIPTextConfig):\n",
    "        super().__init__()\n",
    "        self.text_model = CLIPTextTransformer(config)\n",
    "        # self.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \n",
    "        return self.text_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "        )['pooler_output']\n",
    "        \n",
    "# print(config.text_config.eos_token_id)\n",
    "clip_text_model = CLIPTextModel(config.text_config)\n",
    "text_src = torch.randint(low=0, high=text_config.vocab_size-1, \n",
    "                          size=(batch_size, seq_len),\n",
    "                          dtype=torch.int)\n",
    "\n",
    "text_hidden = clip_text_model(text_src)\n",
    "print(text_hidden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02ede9-06d0-4ede-850a-230312bada0f",
   "metadata": {},
   "source": [
    "## CLIP Vision Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "c6cac220-1dee-45f2-a956-13c88f7325d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPVisionEmbeddings(nn.Module):\n",
    "    def __init__(self, config: CLIPVisionConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed_dim = config.hidden_size\n",
    "        self.image_size = config.image_size\n",
    "        self.patch_size = config.patch_size\n",
    "\n",
    "        self.class_embedding = nn.Parameter(torch.randn(self.embed_dim))\n",
    "\n",
    "        self.patch_embedding = nn.Conv2d(\n",
    "            in_channels=config.num_channels,\n",
    "            out_channels=self.embed_dim,\n",
    "            kernel_size=self.patch_size,\n",
    "            stride=self.patch_size,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.num_patches = (self.image_size // self.patch_size) ** 2\n",
    "        self.num_positions = self.num_patches + 1\n",
    "        self.position_embedding = nn.Embedding(self.num_positions, self.embed_dim)\n",
    "        self.register_buffer(\"position_ids\", torch.arange(self.num_positions).expand((1, -1)), persistent=False)\n",
    "\n",
    "    def forward(self, pixel_values: torch.FloatTensor) -> torch.Tensor:\n",
    "        batch_size = pixel_values.shape[0]\n",
    "        target_dtype = self.patch_embedding.weight.dtype\n",
    "        patch_embeds = self.patch_embedding(pixel_values.to(dtype=target_dtype))  # shape = [*, width, grid, grid]\n",
    "        patch_embeds = patch_embeds.flatten(2).transpose(1, 2)\n",
    "\n",
    "        class_embeds = self.class_embedding.expand(batch_size, 1, -1)\n",
    "        embeddings = torch.cat([class_embeds, patch_embeds], dim=1)\n",
    "        embeddings = embeddings + self.position_embedding(self.position_ids)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class CLIPVisionTransformer(nn.Module):\n",
    "    def __init__(self, config: CLIPVisionConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        embed_dim = config.hidden_size\n",
    "\n",
    "        self.embeddings = CLIPVisionEmbeddings(config)\n",
    "        self.pre_layrnorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\n",
    "        self.encoder = CLIPEncoder(config)\n",
    "        self.post_layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "    ) :\n",
    "        hidden_states = self.embeddings(pixel_values)\n",
    "        hidden_states = self.pre_layrnorm(hidden_states)\n",
    "        encoder_outputs = self.encoder(\n",
    "            hidden_states,\n",
    "        )\n",
    "        last_hidden_state = encoder_outputs\n",
    "        pooled_output = last_hidden_state[:, 0, :] # 第一个token为clstoken\n",
    "        pooled_output = self.post_layernorm(pooled_output)\n",
    "\n",
    "        return { \n",
    "            'last_hidden_state':last_hidden_state,\n",
    "            'pooler_output':pooled_output,\n",
    "        }\n",
    "\n",
    "class CLIPVisionModel(nn.Module):\n",
    "    config_class = CLIPVisionConfig\n",
    "    main_input_name = \"pixel_values\"\n",
    "    _no_split_modules = [\"CLIPEncoderLayer\"]\n",
    "\n",
    "    def __init__(self, config: CLIPVisionConfig):\n",
    "        super().__init__()\n",
    "        self.vision_model = CLIPVisionTransformer(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "    ) -> torch.FloatTensor :\n",
    "\n",
    "        return self.vision_model(\n",
    "            pixel_values=pixel_values,\n",
    "        )['pooler_output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "6c980207-0b02-4814-9ec6-688eb7ed4fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_img = torch.randn(batch_size, num_channels, image_size, image_size)\n",
    "clip_vision_model = CLIPVisionModel(vision_config)\n",
    "x_vision_output = clip_vision_model(x_img)\n",
    "print(x_vision_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decac97c-79ff-4a2d-8411-93f4034d423d",
   "metadata": {},
   "source": [
    "## CLIP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "b7eb26c5-dc89-4f4d-bfea-aa0ccee6aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(logits: torch.Tensor) -> torch.Tensor:\n",
    "    return nn.functional.cross_entropy(logits, torch.arange(len(logits), device=logits.device))\n",
    "\n",
    "\n",
    "def clip_loss(similarity: torch.Tensor) -> torch.Tensor:\n",
    "    caption_loss = contrastive_loss(similarity)\n",
    "    image_loss = contrastive_loss(similarity.t())\n",
    "    return (caption_loss + image_loss) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "42383c76-b053-430c-b954-c39793f6f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPModel(nn.Module):\n",
    "    config_class = CLIPConfig\n",
    "    # _no_split_modules = [\"CLIPTextEmbeddings\", \"CLIPEncoderLayer\", \"CLIPVisionEmbeddings\"]\n",
    "\n",
    "    def __init__(self, config: CLIPConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        text_config = config.text_config\n",
    "        vision_config = config.vision_config\n",
    "\n",
    "        self.projection_dim = config.projection_dim\n",
    "        self.text_embed_dim = text_config.hidden_size\n",
    "        self.vision_embed_dim = vision_config.hidden_size\n",
    "\n",
    "        text_model = CLIPTextModel(text_config)\n",
    "        self.text_model = text_model.text_model\n",
    "\n",
    "        vision_model = CLIPVisionModel(vision_config)\n",
    "        self.vision_model = vision_model.vision_model\n",
    "\n",
    "        self.visual_projection = nn.Linear(self.vision_embed_dim, self.projection_dim, bias=False)\n",
    "        self.text_projection = nn.Linear(self.text_embed_dim, self.projection_dim, bias=False)\n",
    "        self.logit_scale = nn.Parameter(torch.tensor(self.config.logit_scale_init_value))\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        # self.post_init()\n",
    "\n",
    "    # @add_start_docstrings_to_model_forward(CLIP_TEXT_INPUTS_DOCSTRING)\n",
    "    def get_text_features(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        text_outputs = self.text_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = text_outputs[1]\n",
    "        text_features = self.text_projection(pooled_output)\n",
    "\n",
    "        return text_features\n",
    "\n",
    "    \n",
    "    def get_image_features(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "\n",
    "\n",
    "        vision_outputs = self.vision_model(\n",
    "            pixel_values=pixel_values,\n",
    "        )\n",
    "\n",
    "        pooled_output = vision_outputs[1]  # pooled_output\n",
    "        image_features = self.visual_projection(pooled_output)\n",
    "\n",
    "        return image_features\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "    ) :\n",
    "\n",
    "        vision_outputs = self.vision_model(\n",
    "            pixel_values=pixel_values,\n",
    "        )\n",
    "        text_outputs = self.text_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            # position_ids=position_ids,\n",
    "        )\n",
    "\n",
    "        image_embeds = vision_outputs['pooler_output']\n",
    "        image_embeds = self.visual_projection(image_embeds)\n",
    "\n",
    "        text_embeds = text_outputs['pooler_output']\n",
    "        text_embeds = self.text_projection(text_embeds)\n",
    "\n",
    "\n",
    "        # normalized features\n",
    "        image_embeds = image_embeds / image_embeds.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_embeds = text_embeds / text_embeds.norm(p=2, dim=-1, keepdim=True)\n",
    "        print(text_embeds.shape)\n",
    "        print(image_embeds.shape)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_text = torch.matmul(text_embeds, image_embeds.t().to(text_embeds.device)) * logit_scale.to(\n",
    "            text_embeds.device\n",
    "        )\n",
    "        logits_per_image = logits_per_text.t()\n",
    "\n",
    "        loss = None\n",
    "        # if return_loss:\n",
    "\n",
    "        # print(logits_per_text.shape)\n",
    "        # print(logits_per_image.shape)\n",
    "        loss = clip_loss(logits_per_text)\n",
    "\n",
    "        # if not return_dict:\n",
    "        #     output = (logits_per_image, logits_per_text, text_embeds, image_embeds, text_outputs, vision_outputs)\n",
    "        #     return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return {\n",
    "            'loss':loss,\n",
    "            'logits_per_image':logits_per_image,\n",
    "            'logits_per_text':logits_per_text,\n",
    "            'text_embeds':text_embeds,\n",
    "            'image_embeds':image_embeds,\n",
    "            # 'text_model_output':text_outputs,\n",
    "            # 'vision_model_output':vision_outputs,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "ef4f7b24-0588-4a55-a23d-ea6c23411e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model = CLIPModel(config)\n",
    "# print(clip_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a005c5b8-2b31-4fe9-93f0-eec4b56da8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7135</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">DivBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.7135\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(text_src.shape)\n",
    "text_src = torch.randint(low=0, high=text_config.vocab_size-1, \n",
    "                          size=(batch_size, seq_len),\n",
    "                          dtype=torch.int)\n",
    "x_img = torch.randn(batch_size, num_channels, image_size, image_size)\n",
    "clip_output = clip_model(text_src, x_img)\n",
    "print(clip_output['loss'])\n",
    "print(clip_output['image_embeds'].shape)\n",
    "print(clip_output['text_embeds'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5633174-95b6-42c6-b51f-e50e5aec82ff",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662df0b-f27a-4953-8f4d-76cd67e3de81",
   "metadata": {},
   "source": [
    "### CLIP Stage1: Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "301852a6-39b2-4a87-9751-b61d4c0d4ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.1325</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">DivBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2.1325\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "text_src = torch.randint(low=0, high=text_config.vocab_size-1, \n",
    "                          size=(batch_size, seq_len),\n",
    "                          dtype=torch.int)\n",
    "img_src = torch.randn(batch_size, num_channels, image_size, image_size)\n",
    "clip_output = clip_model(text_src, img_src)\n",
    "print(clip_output['loss'])\n",
    "print(clip_output['image_embeds'].shape)\n",
    "print(clip_output['text_embeds'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538b3a9-9303-4f68-853b-1aef7d08c20a",
   "metadata": {},
   "source": [
    "#### modify clip-vision-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "cbe07f6b-bbc6-4929-9400-a4f685af4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLIP zero\n",
    "class CLIPForImageClassification(nn.Module):\n",
    "    main_input_name = \"pixel_values\"\n",
    "\n",
    "    def __init__(self, config: CLIPConfig) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "        self.vision_model = CLIPVisionModel(\n",
    "            config.vision_config\n",
    "        )\n",
    "\n",
    "        # Classifier head\n",
    "        self.classifier = (\n",
    "            nn.Linear(config.vision_config.hidden_size, config.num_labels) if config.num_labels > 0 else nn.Identity()\n",
    "        )\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.vision_model(\n",
    "            pixel_values,\n",
    "        )\n",
    "\n",
    "        print(outputs.shape)\n",
    "        # sequence_output = outputs[0]\n",
    "        \n",
    "\n",
    "        # average pool the patch tokens\n",
    "        # sequence_output = torch.mean(sequence_output[:, 1:, :], dim=1)\n",
    "        # apply classifier\n",
    "        logits = self.classifier(outputs)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_function=nn.CrossEntropyLoss()\n",
    "            loss = loss_function(logits, labels)\n",
    "            print(loss)\n",
    "            \n",
    "        return {\n",
    "            'loss':loss,\n",
    "            'logits':logits,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "8739c70b-27a7-4b84-bbd8-9d645c3508e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIPForImageClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "9d28de33-c41e-4458-a9f5-25f8d668112a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.3959</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">NllLossBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2.3959\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mNllLossBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.3959</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">NllLossBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2.3959\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mNllLossBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "# text_src = torch.randint(low=0, high=text_config.vocab_size-1, \n",
    "#                           size=(batch_size, seq_len),\n",
    "#                           dtype=torch.int)\n",
    "config.num_labels = 10\n",
    "img_src = torch.randn(batch_size, num_channels, image_size, image_size)\n",
    "clip_vision_classifier = CLIPForImageClassification(config)\n",
    "\n",
    "# labels = torch.randint(low=0, high=config.num_labels, \n",
    "#                           size=(1,batch_size),\n",
    "#                           dtype=torch.long)\n",
    "# labels = labels.view(-1)\n",
    "print(logits.shape)\n",
    "print(logits.shape)\n",
    "labels = torch.empty(batch_size, dtype=torch.long).random_(config.num_labels)\n",
    "\n",
    "\n",
    "result = clip_vision_classifier(img_src, labels=labels)\n",
    "# print(result)\n",
    "print(result['logits'].shape)\n",
    "print(result['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9edda-0df2-4c33-aab2-a80efe4fe7de",
   "metadata": {},
   "source": [
    "## CLIP stage2: ZeroShot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "3e3c5697-cdd9-48fd-8dc3-bbd38ad58273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27848</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36988</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8743</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47788</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m7\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m27848\u001b[0m, \u001b[1;36m10838\u001b[0m, \u001b[1;36m36988\u001b[0m,  \u001b[1;36m8743\u001b[0m, \u001b[1;36m47788\u001b[0m,     \u001b[1;36m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_model.vision_model\n",
    "clip_model.text_model\n",
    "\n",
    "\n",
    "one_img_src = torch.randn(1, num_channels, image_size, image_size)\n",
    "\n",
    "\n",
    "seq_len = 5\n",
    "config.num_labels = 10\n",
    "\n",
    "text_prompt_src = torch.randint(low=0, high=text_config.vocab_size-1, \n",
    "                          size=(1, seq_len),\n",
    "                          dtype=torch.int)\n",
    "\n",
    "text_prompt_src = text_prompt_src.expand(config.num_labels, -1)\n",
    "print(text_prompt_src)\n",
    "\n",
    "class_object_token = torch.arange(config.num_labels).unsqueeze(-1)\n",
    "print(class_object_token)\n",
    "\n",
    "\n",
    "prompt = torch.cat( (text_prompt_src,class_object_token), 1 )\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d36ca874-8543-4ae4-b893-d357e441802c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0028</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0718</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0284</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0015</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0214</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0263</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0603</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0013</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0296</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0057</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">MmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0028\u001b[0m,  \u001b[1;36m0.0718\u001b[0m, \u001b[1;36m-0.0284\u001b[0m, \u001b[1;36m-0.0015\u001b[0m,  \u001b[1;36m0.0214\u001b[0m, \u001b[1;36m-0.0263\u001b[0m, \u001b[1;36m-0.0603\u001b[0m,  \u001b[1;36m0.0013\u001b[0m,\n",
       "          \u001b[1;36m0.0296\u001b[0m,  \u001b[1;36m0.0057\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# clip_output = clip_model(prompt, one_img_src)\n",
    "# print(clip_output['loss'])\n",
    "print(clip_output['image_embeds'].shape)\n",
    "print(clip_output['text_embeds'].shape)\n",
    "\n",
    "\n",
    "vision_outputs = clip_model.vision_model(\n",
    "    pixel_values=one_img_src,\n",
    ")['pooler_output']\n",
    "text_outputs = clip_model.text_model(\n",
    "    input_ids=prompt,\n",
    "    # attention_mask=attention_mask,\n",
    ")['pooler_output']\n",
    "\n",
    "image_embeds = clip_model.visual_projection(vision_outputs)\n",
    "text_embeds = clip_model.text_projection(text_outputs)\n",
    "print(image_embeds.shape)\n",
    "print(text_embeds.shape)\n",
    "\n",
    "# normalized features\n",
    "image_embeds = image_embeds / image_embeds.norm(p=2, dim=-1, keepdim=True)\n",
    "text_embeds = text_embeds / text_embeds.norm(p=2, dim=-1, keepdim=True)\n",
    "\n",
    "logits = image_embeds@text_embeds.transpose(1,0)\n",
    "print(logits)\n",
    "torch.argmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd81fafc-7ee1-44ef-9e36-968ad51203e7",
   "metadata": {},
   "source": [
    "## Pretrained data prepare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
