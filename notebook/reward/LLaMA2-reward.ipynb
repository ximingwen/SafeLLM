{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d235f47d",
   "metadata": {},
   "source": [
    "# Reward Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a38b74-35e0-4059-b5a9-0db37c642561",
   "metadata": {},
   "source": [
    "## 模型结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f36619-539d-4627-92d4-ab7156b66e0c",
   "metadata": {},
   "source": [
    "![reward](./llama2reward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f200f-85af-430c-86d9-d1ff79e337d5",
   "metadata": {},
   "source": [
    "> 3.2.2 Reward Modeling\n",
    "> \n",
    "> The model architecture and hyper-parameters are identical to those\n",
    "> of the pretrained language models, except that the classification head for next-token prediction is replaced\n",
    "> with a regression head for *outputting a scalar reward*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "629fcdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at ./lm_pretrained and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LlamaForSequenceClassification</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LlamaModel</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>embed_tokens<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>layers<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LlamaDecoderLayer</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>self_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LlamaSdpaAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>q_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>k_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>v_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>o_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LlamaRotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LlamaMLP</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>gate_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>up_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>down_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>act_fn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SiLU</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>input_layernorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LlamaRMSNorm</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">(</span>post_attention_layernorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LlamaRMSNorm</span><span style=\"font-weight: bold\">()</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LlamaRMSNorm</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>score<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLlamaForSequenceClassification\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m: \u001b[1;35mLlamaModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0membed_tokens\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mLlamaDecoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mself_attn\u001b[1m)\u001b[0m: \u001b[1;35mLlamaSdpaAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mq_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mk_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mv_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mo_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mLlamaRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mLlamaMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mgate_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mup_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdown_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact_fn\u001b[1m)\u001b[0m: \u001b[1;35mSiLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0minput_layernorm\u001b[1m)\u001b[0m: \u001b[1;35mLlamaRMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpost_attention_layernorm\u001b[1m)\u001b[0m: \u001b[1;35mLlamaRMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mLlamaRMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mscore\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import LlamaModel, LlamaConfig, LlamaForCausalLM, LlamaForSequenceClassification\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 加载模型\n",
    "config = LlamaConfig(vocab_size = 100,      # default is 32000\n",
    "                    hidden_size = 256,\n",
    "                    intermediate_size = 512,\n",
    "                    num_hidden_layers = 2,\n",
    "                    num_attention_heads = 4,\n",
    "                    num_key_value_heads = 4,\n",
    "                    )\n",
    "model = LlamaForCausalLM(config)\n",
    "model.save_pretrained('./lm_pretrained')\n",
    "rm_model = LlamaForSequenceClassification.from_pretrained('./lm_pretrained', num_labels=1)\n",
    "\n",
    "print(rm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a832b61-9c40-43dc-9840-0027f3231be7",
   "metadata": {},
   "source": [
    "## 模型训练+margin loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23639462-f2b3-45fa-b6e1-e44e372c6644",
   "metadata": {},
   "source": [
    "$L=-\\log(\\sigma(r_{\\theta}(x,y_c)-r_{\\theta}(x,y_r)-m(r)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58697d-71a8-4a16-8a0b-76aa4d339d1d",
   "metadata": {},
   "source": [
    "where the margin $m(r)$ is a discrete function of the preference rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d96a2388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">prompt chosen reward : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17402283847332</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "prompt chosen reward : \u001b[1;36m0.17402283847332\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">prompt rejected reward : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2538455128669739</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "prompt rejected reward : \u001b[1;36m-0.2538455128669739\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">reward model loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5019243955612183</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "reward model loss: \u001b[1;36m0.5019243955612183\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">reward model loss with margin: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.645728349685669</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "reward model loss with margin: \u001b[1;36m2.645728349685669\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_chosen = torch.randint(0, 100, (1,10))\n",
    "X_rejected = torch.randint(0, 100, (1,10))\n",
    "margin = 3.0 # Margin Large : Significantly Better \n",
    "\n",
    "idx={}\n",
    "idx['input_ids'] = X_chosen\n",
    "rm_chosen = rm_model(**idx).logits\n",
    "\n",
    "idx['input_ids'] = X_rejected\n",
    "rm_rejected = rm_model(**idx).logits\n",
    "\n",
    "loss = -torch.sigmoid(rm_chosen - rm_rejected).log()\n",
    "loss_with_margin = -torch.sigmoid(rm_chosen - rm_rejected - margin).log()\n",
    "\n",
    "print( f'prompt chosen reward : {rm_chosen.item()}')\n",
    "print( f'prompt rejected reward : {rm_rejected.item()}')\n",
    "print( f'reward model loss: {loss.item()}')\n",
    "print( f'reward model loss with margin: {loss_with_margin.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721ffff-0705-4ba0-9667-dbed8b7f36fe",
   "metadata": {},
   "source": [
    "## 模型推理 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0c103b8-db61-438a-97d2-9b229838ec02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">93</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m93\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m99\u001b[0m, \u001b[1;36m26\u001b[0m, \u001b[1;36m49\u001b[0m, \u001b[1;36m22\u001b[0m, \u001b[1;36m37\u001b[0m, \u001b[1;36m52\u001b[0m, \u001b[1;36m17\u001b[0m, \u001b[1;36m51\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">reward result: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2538455128669739</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "reward result: \u001b[1;36m-0.2538455128669739\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.randint(0, 100, (1,10))\n",
    "rm_model.eval()\n",
    "rm_score = rm_model(**idx).logits\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print('reward result:', rm_score.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2decb4b-4730-4031-9832-fade863fd442",
   "metadata": {},
   "source": [
    "##  双reward选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4304b-6026-42ae-893d-4bf2e32e563d",
   "metadata": {},
   "source": [
    "$$ R_c(g | p) = \\begin{cases} R_s(g|p)& \\text{if } \\text{is\\_safety}(p) \\text{ or } R_s(g \\mid p) < 0.15 \\\\ R_h(g|p) & \\text{otherwise} \\end{cases} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ac6f42-3953-4e20-b0d4-965835108d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m-0.3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0.4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def llama2_reward_select(reward_safety, reward_helpfulness):\n",
    "    return reward_safety if reward_safety < 0.15 else reward_helpfulness\n",
    "    \n",
    "rc = llama2_reward_select(reward_safety=-0.3,  reward_helpfulness=0.7)\n",
    "print(rc)\n",
    "rc = llama2_reward_select(reward_safety=1.3,  reward_helpfulness=0.4)\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dfd5b0-afd6-46b1-b9cb-256bbcbf1863",
   "metadata": {},
   "source": [
    "## 逆Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945518a0-fb2e-4129-a4c2-50f1b66f176b",
   "metadata": {},
   "source": [
    "> We also find it important to whiten\n",
    "> the final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\n",
    "> stability and balance properly with the KL penalty term (β) above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f0f27-a2f1-44d4-9524-182bf19682ed",
   "metadata": {},
   "source": [
    "$$\\hat{R}={\\text{WHITEN}}({\\color{red}{\\text{LOGIT}}(R_c(g|p)}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b85f3f1d-45aa-42e8-832b-1dbb8d87aaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">逆Sigmoid输出： <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.1972</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "逆Sigmoid输出： \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2.1972\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">逆Sigmoid输出： <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "逆Sigmoid输出： \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">逆Sigmoid输出： <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.5951</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "逆Sigmoid输出： \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-4.5951\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 实际reward已经输出标量，无须加入以下操作\n",
    "# 代码仅以复现为目标\n",
    "def inverse_sigmoid(x):\n",
    "    return torch.log(x / (1 - x))\n",
    "\n",
    "sigmoid_output = torch.tensor([0.9])\n",
    "inverse_sigmoid_output = inverse_sigmoid(sigmoid_output)\n",
    "print(\"逆Sigmoid输出：\", inverse_sigmoid_output)\n",
    "\n",
    "sigmoid_output = torch.tensor([0.5])\n",
    "inverse_sigmoid_output = inverse_sigmoid(sigmoid_output)\n",
    "print(\"逆Sigmoid输出：\", inverse_sigmoid_output)\n",
    "\n",
    "sigmoid_output = torch.tensor([0.01])\n",
    "inverse_sigmoid_output = inverse_sigmoid(sigmoid_output)\n",
    "print(\"逆Sigmoid输出：\", inverse_sigmoid_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59de766-2857-42b5-81d9-5388229dd9d6",
   "metadata": {},
   "source": [
    "## Whiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee9488-f163-4046-ab2f-932918ebcd0d",
   "metadata": {},
   "source": [
    "$$\\hat{R}_c(g|p)={\\color{red}{\\text{WHITEN}}}({\\text{LOGIT}}(R_c(g|p)))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c015f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">whiten前： <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8300</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.6000</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "whiten前： \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.8300\u001b[0m, \u001b[1;36m1.2000\u001b[0m, \u001b[1;36m3.3000\u001b[0m, \u001b[1;36m4.6000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">whiten后： <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.9273</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.7197</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4587</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1882</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "whiten后： \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.9273\u001b[0m, \u001b[1;36m-0.7197\u001b[0m,  \u001b[1;36m0.4587\u001b[0m,  \u001b[1;36m1.1882\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">whiten前： <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.8300</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101.2000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">103.3000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">104.6000</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "whiten前： \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100.8300\u001b[0m, \u001b[1;36m101.2000\u001b[0m, \u001b[1;36m103.3000\u001b[0m, \u001b[1;36m104.6000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">whiten后： <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.9273</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.7197</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4587</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1882</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "whiten后： \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.9273\u001b[0m, \u001b[1;36m-0.7197\u001b[0m,  \u001b[1;36m0.4587\u001b[0m,  \u001b[1;36m1.1882\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def whiten(values: torch.Tensor, shift_mean: bool = True) -> torch.Tensor:\n",
    "    mean, var = torch.mean(values), torch.var(values)\n",
    "    whitened = (values - mean) * torch.rsqrt(var + 1e-8)\n",
    "    if not shift_mean:\n",
    "        whitened += mean\n",
    "    return whitened\n",
    "\n",
    "values = torch.tensor([[0.8300, 1.2000, 3.3000, 4.6000]])\n",
    "values_whiten = whiten(values)\n",
    "print('whiten前：', values)\n",
    "print('whiten后：', values_whiten)\n",
    "\n",
    "\n",
    "values = torch.tensor([[100.8300, 101.2000, 103.3000, 104.6000]])\n",
    "values_whiten = whiten(values)\n",
    "print('whiten前：', values)\n",
    "print('whiten后：', values_whiten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd1276-0a21-4b8e-a10d-7d4f5a440c5b",
   "metadata": {},
   "source": [
    "## KL penalty "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063e8bc-79e8-4e20-8198-6e6e1d1acb4f",
   "metadata": {},
   "source": [
    "$$R(g|p)=\\hat{R}_c(g|p)-\\color{red}{\\beta D_{KL}(\\pi_{\\theta}(g|p)||\\pi_{0}(g|p))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "af9ca0ad-a353-420c-b756-522132351b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">old policy index: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">94</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "old policy index: \u001b[1;36m94\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">old policy prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.19441646337509155</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "old policy prob: \u001b[1;36m0.19441646337509155\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">policy prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5318925976753235</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "policy prob: \u001b[1;36m0.5318925976753235\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">kl penalty: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1956683099269867</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "kl penalty: \u001b[1;36m-0.1956683099269867\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">rm_score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2538455128669739</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "rm_score: \u001b[1;36m-0.2538455128669739\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">beta: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "beta: \u001b[1;36m0.01\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">rm_score with kl <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.25188884139060974</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "rm_score with kl \u001b[1;36m-0.25188884139060974\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model = LlamaForCausalLM(config) # actor model\n",
    "model_old = LlamaForCausalLM(config) # actor model\n",
    "\n",
    "# old policy\n",
    "index_old = torch.randint(0, 100, (1,1)) # select policy\n",
    "prob_old = torch.rand(1,1)\n",
    "print('old policy index:', index_old.item())\n",
    "print('old policy prob:',  prob_old.item())\n",
    "\n",
    "# new policy\n",
    "output = model(X)['logits'][:,-1,:].sigmoid()\n",
    "prob = torch.gather(output, dim=1, index=index_old)\n",
    "print('policy prob:', prob.item())\n",
    "\n",
    "# calculative kl \n",
    "# kl = F.kl_div(torch.log(prob), prob_old.detach, reduction='sum') \n",
    "kl = F.kl_div(torch.log(prob), prob_old)\n",
    "print('kl penalty:', kl.item())\n",
    "\n",
    "# final reward\n",
    "beta = 0.01\n",
    "rm_score = rm_model(**idx).logits\n",
    "rm_ppo = rm_score - beta * kl\n",
    "print('rm_score:', rm_score.item())\n",
    "print('beta:', beta)\n",
    "print('rm_score with kl', rm_ppo.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31f7e5e-1929-423b-905f-a317238d6931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
